Automated Text Analysis for Consumer
Research

ASHLEE HUMPHREYS
REBECCA JEN-HUI WANG
The amount of digital text available for analysis by consumer researchers has risen
dramatically. Consumer discussions on the internet, product reviews, and digital
archives of news articles and press releases are just a few potential sources for
insights about consumer attitudes, interaction, and culture. Drawing from linguistic
theory and methods, this article presents an overview of automated text analysis,
providing integration of linguistic theory with constructs commonly used in consumer
research, guidance for choosing amongst methods, and advice for resolving sampling
and statistical issues unique to text analysis. We argue that although automated text
analysis cannot be used to study all phenomena, it is a useful tool for examining patterns in text that neither researchers nor consumers can detect unaided. Text analysis
can be used to examine psychological and sociological constructs in consumerproduced digital text by enabling discovery or by providing ecological validity.
Keywords: automated text analysis, computer-assisted text analysis, automated
content analysis, computational linguistics
Over the last two decades, researchers have seen an explosion of text data generated by consumers in the
form of text messages, reviews, tweets, emails, posts, and
blogs. Some part of this rise is attributed to an increase in
sites like Amazon.com, CNET.com, and thousands of other
product websites that offer forums for consumer comment.
Another part of this growth comes from consumergenerated content, including discussions of products, hobbies, or brands on feeds, message boards, and social networking sites. Researchers, consumers, and marketers
swim in a sea of language, and more and more of that language is recorded in the form of text. Yet within all of this
information lies knowledge about consumer decision
making, psychology, and culture that may be useful to
scholars in consumer research. Blogs can be used to study
opinion leadership; message boards can tell us about the
development of consumer communities; feeds like Twitter
can help us unpack social media firestorms; and social
commerce sites like Amazon can be mined for details
about word-of-mouth communication.
Correspondingly, ways of doing social science are also
changing. Because data has become more readily available
and the tools and resources for analysis are cheaper and more
accessible, researchers in the material sciences, humanities,
and social sciences are developing new methods of datadriven discovery to deal with what some call the “data deluge” or “big data” (Bell, Hey, and Szalay 2009; Borgman
2015). Just as methods for creating, circulating, and storing
online discussion have grown more sophisticated, so too
Ashlee Humphreys (humphreys@northwestern.edu) is an associate
professor of integrated marketing communications at the Medill School
of Journalism, Media, and Integrated Marketing Communications,
Northwestern University, MTC 3-109, 1870 Campus Drive, Evanston, IL
60208. Rebecca Jen-Hui Wang (rwang@lehigh.edu) is an assistant professor at Lehigh University, 621 Taylor Street, Bethlehem, PA 18015.
Correspondence concerning this article should be addressed to Ashlee
Humphreys. The authors would like to thank David Dubois, Alistair Gill,
Jonathan Berman, Grant Packard, Ann Kronrod, Joseph T. Yun, Jonah
Berger, and Kent Grayson for their feedback and encouragement on the
manuscript, and Andrew Wang for his help with data collection for the
web appendix. The authors would also like to thank the editor, associate
editor, and reviewers for their helpful guidance, comments, and suggestions. The authors would also like to thank the editor, associate editor, and
reviewers for their helpful guidance, comments, and suggestions.
Supplementary materials are included in the web appendix accompanying
the online version of this article.
Eileen Fischer served as editor and Linda Price served as associate editor
for this article.
Advance Access publication September 29, 2017
VC The Author 2017. Published by Oxford University Press on behalf of Journal of Consumer Research, Inc.
All rights reserved. For permissions, please e-mail: journals.permissions@oup.com  Vol. 44  2018
DOI: 10.1093/jcr/ucx104
1274
Downloaded from https://academic.oup.com/jcr/article-abstract/44/6/1274/4283031
by Galter Health Sciences Library, Northwestern Univ. user
on 15 June 2018
have tools for analyzing language, aggregating insight, and
distilling knowledge from this overwhelming amount of
data. Yet despite the potential importance of this shift,
consumer research is only beginning to incorporate methods
for collecting and systematically measuring textual data to
support theoretical propositions and make discoveries.
In light of the recent influx of available data and the lack
of an overarching framework for doing consumer research
using text, the goal of this article is to provide a guide for research designs that incorporate text and to help researchers
assess when and why text analysis is useful for answering
consumer research questions. We provide an overview of
both deductive top-down, dictionary-based approaches as
well as inductive and abductive bottom-up approaches such
as supervised and unsupervised learning to incorporate
discovery-oriented as well as theoretically guided methods.
These designs help make discoveries and expand theory by
allowing computers to detect and display patterns that
humans cannot and by providing new ways of “seeing” data
through aggregation, comparison, and correlation. We further offer guidance for choosing amongst different methods
and address common issues unique to text analysis, such as
sampling internet data, developing word lists to represent a
construct, and analyzing sparse, non-normally distributed
data. We also address validity, reliability, generalizability,
and ethical issues for research using textual data.
Although there are many ways to incorporate automated
text analysis into consumer research, there is not much
agreement on the standard set of methods, reporting procedures, steps of data inclusion, exclusion, and sampling,
and, where applicable, dictionary development and validation. Nor has there been an integration of the linguistic theory on which these methods are based into consumer
research, which can enlighten us to the multiple dimensions of language that can be used to measure consumer
thought, interaction, and culture. While fields like psychology provide some guidance for dictionary-based methods
(Tausczik and Pennebaker 2010) and for analysis of certain
types of social media data (Kern et al. 2016), they don’t
provide grounding in linguistics, cover the breadth of
methods available for studying text, or provide criteria for
deciding amongst approaches. In short, most of the existing
literature examines only a handful of aspects of discourse
that pertain to the research questions of interest, does not
address why one method is chosen over others, and does
not discuss the unique methodological issues consumer
researchers face when dealing with text.
This article therefore offers three contributions to consumer research. First, we detail how linguistic theory can inform theoretical areas common in consumer research, such
as attention, processing, interpersonal interaction, group dynamics, and cultural characteristics. Second, we outline a
practical roadmap for researchers who want to use textual
data, particularly unstructured text obtained from real-world
settings, such as tweets, newspaper articles, or online
reviews. Lastly, we examine what can and cannot be done
with text analysis and provide guidance for validating results
and interpreting findings in non-experimental contexts.
The rest of the article is organized around the roadmap
in figure 1. This chart presents a series of decisions a researcher faces when analyzing text. We outline six stages:
(1) developing a research question, (2) identifying the constructs, (3) collecting data, (4) operationalizing the constructs, (5) interpreting the results, and (6) validating the
results. Although text analysis need not necessarily unfold
in this order (for instance, construct definition will sometimes occur after data collection), researchers have generally followed this progression (Lee and Bradlow 2011).
ROADMAP FOR AUTOMATED TEXT
ANALYSIS
Methods of automated text analysis come from the field of
computational linguistics (Kranz 1970; Stone 1966). The relationship between computational linguistics and text analysis is analogous to that of biology to medicine or of physics
to engineering. That is, computational linguistics, at its core,
emphasizes advancing linguistics theory and often focuses
on the accuracy of prediction as an end in itself (Hausser
1999, 8). Computer-assisted or automated text analysis, on
the other hand, refers to a set of techniques that use computing power to answer questions related to psychology (Chung
and Pennebaker 2013; Tausczik and Pennebaker 2010), political science (Grimmer and Stewart 2013), sociology (Mohr
1998; Shor et al. 2015), and other social sciences (Carley
1997; Weber 2005). In these fields, language represents
some focal construct of interest, and computers are used to
measure those constructs, provide systematic comparisons,
and sometimes find patterns that neither human researchers
nor subjects of the research can detect. In other words, while
computational linguistics is a field that is primarily concerned with language in the text, for consumer researchers,
text analysis is merely a lens through which to view consumer thought, behavior, and culture. Analyzing texts, in
many contexts, is not the ultimate goal of consumer researchers, but is instead a precursor for testing the relationship between or amongst the constructs or variables of interest.
Therefore, we use the term “automated text analysis” or
“computer-assisted text analysis” over “computational linguistics” (Brier and Hopp 2011). Although we follow convention
by using the term “automated,” this should not imply that human intervention is absent. In fact, many of the tasks—such as
dictionary construction, validation, and cluster labeling—are
iterative processes that require human design, modification,
and interpretation. Some prefer the term “computer-assisted
text analysis” (Alexa 1997) to explicitly encompass a broad
set of methods that take advantage of computation in
HUMPHREYS AND WANG 1275
Downloaded from https://academic.oup.com/jcr/article-abstract/44/6/1274/4283031
by Galter Health Sciences Library, Northwestern Univ. user
on 15 June 2018
varying amounts ranging from a completely automated process using machine learning to researcher-guided
approaches that include manual coding and word list development. In the following sections, we discuss the design and
execution of automated text analysis in detail, beginning
with selection of a research question and connecting linguistic aspects to important constructs in consumer research.
STAGE 1: DEVELOP A RESEARCH
QUESTION
As with any research, the first step is developing a research question. To understand the implementation of automated text analysis, one should start by first considering if
the research question lends itself to text analysis.
Contemplating whether text analysis is suitable for the research context is perhaps the most important decision to
consider, and there are at least three purposes for which
text analysis would be inappropriate.
First, much real-world textual content is observational
data that occurs without the controlled conditions of an experiment or even a field test. Depending on the context and
research question, automated text analysis alone would not
be the best method for inferring causation when studying a
psychological mechanism.1 If the researcher needs precise
control to compare groups, introduce manipulations, or
rule out alternative hypotheses through random assignment
protocols (Cook, Campbell, and Day 1979), textual analysis would be of limited use.2
Secondly, if the research question concerns data at the
behavioral or unarticulated level (e.g., response time,
skin conductance, consumer practices), text analysis
would not be appropriate. Neural mechanisms that govern
perception or attention, for example, would be ill suited
for the method. Equally, if one needs a behavioral dependent variable, text analysis would not be appropriate to
measure it. For example, when one is studying selfregulation, it is clearly important to include behavioral
measures to examine not just behavioral intention—what
people say they will do—but action itself. This restriction
applies to sociologically oriented research as well. For
example, with practice theory (Allen 2002; Schatzki
1996) or ethnography (Belk, Sherry, and Wallendorf
1988; Schouten and McAlexander 1995), observation of
consumer practices is vital because consumer behavior
may diverge markedly from discourse (Wallendorf and
Arnould 1988). Studying text is simply no substitute for
studying behavior. Not all constructs lend themselves to
examination through text, and these constructs tend to be
behaviorally oriented.
FIGURE 1
STAGES OF AUTOMATED TEXT ANALYSIS
1 For alternative perspectives of studying causation with historical
case data and macro-level data, see Mahoney and Rueschemeyer
(2003) and Jepperson and Meyer (2011).
2 However, text analysis has been used to code thought protocols in
experimental settings (Hsu et al. 2014).
1276 JOURNAL OF CONSUMER RESEARCH
Downloaded from https://academic.oup.com/jcr/article-abstract/44/6/1274/4283031
by Galter Health Sciences Library, Northwestern Univ. user
on 15 June 2018
Lastly, there are many contexts in which some form of
text analysis would be valuable, but automated text analysis would be insufficient. Identifying finer shades of meaning, such as sarcasm, and differentiating amongst complex
concepts, rhetorical strategies, or complex arguments are
often not possible via automated processes. Additionally,
studies that employ text analysis often sample data from
public discourse in the form of tweets, message boards, or
posts, and there is a wide range of expression that consumers may not pursue in these media because of stigma or social desirability. There is a rich tradition of text analysis in
consumer research, such as discourse analysis (Holt and
Thompson 2004; Thompson and Hirschman 1995), hermeneutic analysis (Arnold and Fischer 1994; Thompson,
Locander, and Pollio 1989), and human content analysis
(Kassarjian 1977) for uncovering rich, deep, and sometimes personal meaning of consumer life in the context in
which it is lived. Although automated text analysis could
be a companion to these methods, it cannot be a standalone
approach for understanding this kind of richer, deeper, and
culturally laden meaning.
So, when is automated text analysis appropriate? In general, it is good for analyzing data in a context where humans
may be limited or partial. Computers can sometimes see patterns in language that humans cannot detect, and they are
impartial in the sense that they measure textual data evenly
and precisely over time or in comparisons between groups
without preconception. Further, by quantifying constructs in
text, computers provide new ways of aggregating and displaying information to uncover patterns that may not be obvious at the granular level. There are at least four types of
problems where these advantages can be leveraged.
First, automated text analysis can lead to discoveries of
systematic relationships in text and hence amongst constructs that may be overlooked by researchers or consumers
themselves. Patterns in correlation, notable absences, and
relationships amongst three or more textual elements are
all things that are simply hard for a human reader to see.
For example, in medical research, Swanson (1988) finds a
previously unrecognized relationship between migraine
headaches and magnesium levels through the text analysis
of other, seemingly unrelated research. Automated text
analysis may also provide alternative ways of “reading”
the text to make new discoveries (Kirschenbaum 2007).
For instance, Jurafsky et al. (2014) find expected patterns
in negative restaurant reviews, such as negative emotion
words, but they also discover words like “after,” “would,”
and “should” in these reviews, which are used to construct
narratives of interpersonal trauma primarily based on
norm violations. Positive restaurant reviews, on the other
hand, contain stories of addiction rather than simple positive descriptions of food or service. These discoveries,
then, theoretically inform researchers’ understanding of
negative and positive sentiment, particularly in the context of consumer experiences.
Using text analysis, researchers have also discovered important differences between expert and consumer discourse
when evaluating products (Lee and Bradlow 2011; Netzer
et al. 2012). In the case of cameras, for example, systematic
linguistic comparison of expert reviews to consumer reviews
reveals that there is a significant disconnect between what
each of these groups considers important. For example, in
their reviews, consumers value observable attributes like
camera size and design, while experts stress less visible
issues like flash range and image compression (Lee and
Bradlow 2011). In the case of prescription drugs, the differences between consumers and experts take on heightened
meaning, as textual comparison of patient feedback of drugs
on WebMD shows that consumers report side effects missing from the official medical literature (Netzer et al. 2012).
In this way, text analysis can reveal discoveries that would
be hard to detect on a more granular level. Further, The
scope and systematicity of the analysis can grant more validity and perhaps power to consumers’ point of view.
Second, researchers can use computers to execute rules
impartially in order to measure changes in language over
time, compare between groups, or aggregate large amounts
of text. These tasks are more than mere improvements in
efficiency in that they present an alternative way of
“seeing” the text through conceptual maps (Martin,
Pfeffer, and Carley 2013), timelines (Humphreys and
Latour 2013), or networks (Arvidsson and Caliandro
2016), and provide information about rate and decay. For
example, using features like geolocation and timestamps
along with textual data from Twitter, Snefjella and
Kuperman (2015) develop new knowledge about construal
level such as its rate of change given a speaker’s physical,
temporal, social, or topical proximity.
Providing an explicit rule set and having a computer execute the rules over the entire dataset, reduces the possibility that texts will be analyzed unevenly or incompletely.
This is especially important when researchers are making
statistical inferences about changes in concepts over time,
because it ensures that measurement is consistent throughout
the dataset. For example, by aggregating and placing counts
of hashtags on a timeline, Arvidsson and Caliandro (2016)
demonstrate how networks of concepts used to discuss
Louis Vuitton handbags peak at particular times and in accordance with external events, highlighting attention for a
particular public. If a researcher wants to study a concept
like brand meaning, text analysis can help to create conceptual or positioning maps that represent an aggregated picture
of consumer perceptions that can then be used to highlight
potential gaps or tensions in meaning amongst different constituencies or even for one individual (Lee and Bradlow
2011; Netzer et al. 2012).
Third, text analysis can be a valuable companion to experimental research designs by adding ecological validity
to lab results. For example, Mogilner et al. (2011) find robust support for changes in the frame of happiness that
HUMPHREYS AND WANG 1277
Downloaded from https://academic.oup.com/jcr/article-abstract/44/6/1274/4283031
by Galter Health Sciences Library, Northwestern Univ. user
on 15 June 2018
correspond with age by looking at a large dataset of personal blogs, patterns they also find in a survey and laboratory experiment. In a study of when and why consumers
explain choices as a matter of taste versus quality, Spiller
and Belogolova (2016) use text analysis first to code a dependent variable in experimental analysis, but then add robustness to their results by demonstrating the effect in the
context of online movie reviews. In this way, text analysis
is valuable beyond its more traditional uses for coding
thought protocols, but also useful for finding and measuring psychological and sociological constructs in naturally
occurring consumer discourse.
Lastly, there are some relationships for which observational data is the most natural way to study the phenomenon.
Interpersonal relationships and group interaction can be hard
to study in the lab, but they can be examined through text
analysis of online interaction or transcripts of recorded conversation (Jurafsky, Ranganath, and McFarland 2009). For
example, Barasch and Berger (2014) combine laboratory
studies with dictionary-based text analysis of consumer discussions to show that consumers share different information
depending on the size of their audience.
Given these considerations, once it is established that text
analysis is appropriate for some part of the research design,
the next question is what role it will play. Text could be
used to represent the independent variable (IV), dependent
variable (DV), or both. For example, Tirunillai and Tellis
(2012) operationalize “chatter” using quantity and valence
of product reviews to represent the IV, which predicts firm
performance in the financial stock market. Conversely, Hsu
et al. (2014) experimentally manipulate distraction, the IV,
and measure thoughts as the DV using text analysis. Other
studies use text as both the IV and the DV. For example,
Humphreys (2010) examines how terms related to casino
gambling and entertainment in newspaper articles converged
over time along with a network of other concepts such as
luxury and money, while references to illegitimate frames
like crime fell. As these cases illustrate, text analysis is a
distinct component of the research design, to be executed
and then incorporated into the overall design.
More generally, text analysis can occupy different places
in the scientific process, depending on the interests and orientation of the researchers. It is compatible with both theory
testing and discovery-oriented designs. For some, text analysis is a way of first discovering patterns that are later verified through laboratory experiments (Barasch and Berger
2014; Berger and Milkman 2012; Packard and Berger
2016). Others use text analysis to enrich findings after investigating a psychological or social mechanism (Mogilner
et al. 2011; Spiller and Belogolova 2016). In the same way,
sociological work has used text analysis to illustrate findings
after an initial discovery phase through qualitative analysis
(Arsel and Bean 2013; Humphreys 2010), or to set the stage
by presenting sociocultural discourses prior to individual or
group-level analysis (Arsel and Thompson 2011).
STAGE 2: IDENTIFY THE CONSTRUCT
After one has decided that text analysis might be appropriate for the research question, the next step is to identify
the construct. Doing so, however, entails recognizing that
text is ultimately based on language. To build sound hypotheses and make valid conclusions from text, one must
first understand the underpinnings of language.
Language indelibly shapes how humans view the world
(Piaget 1959; Quine 1970; Vico 1725/1984; Whorf 1944).
It can be both representative of thought and instrumental in
shaping thought (Kay and Kempton 1984; Lucy and
Shweder 1979; Sapir 1929; Schmitt and Zhang 1998; see
also Graham 1981; Whorf 1944). For example, studies
have shown that languages with gendered nouns, like
Spanish and French, are more likely to make speakers think
of physical objects as having a gender (Boroditsky,
Schmidt, and Phillips 2003; Sera, Berge, and del Castillo
Pintado 1994). Languages like Mandarin that speak of time
vertically rather than horizontally shape native speakers’
perceptions of time (Boroditsky 2001), and languages like
Korean that emphasize social hierarchy reflect this value in
the culture (McBrian 1978). These effects underscore the
fact that by studying language, consumer researchers are
studying thought and that language is conversely important
because it shapes thought.
As a sign system, language has three aspects—semantic,
pragmatic, and syntactic (Mick 1986; Morris 1994)—each
of which provides a unique window into a slightly different
part of consumer thought, interaction, or culture.
Semantics concerns word meaning that is explicit in linguistic content (Frege 1892/1948), while pragmatics
addresses the interaction between linguistic content and
extra-linguistic factors like context or the relationship between speaker and hearer (Grice 1975). Syntax focuses on
grammar, the order in which linguistic elements are presented (Chomsky 1957/2002). By understanding and appreciating these linguistic underpinnings, researchers can
develop sounder operationalizations of the constructs and
more insightful, novel hypotheses. We will discuss semantics, pragmatics, and syntax in turn as they are relevant to
constructs in consumer research. Extensive treatment of
these properties can be found in Mick (1986), although previous use of semiotics in consumer research has been focused primarily on objects and images as signs (Grayson
and Shulman 2000; McQuarrie and Mick 1996; Mick
1986; Sherry, McGrath, and Levy 1993) rather than on language itself. In discussing construct identification, we link
linguistic theory to topics of interest in consumer research—attention, processing, social influence, and group
properties.
To more fully understand what kinds of problems might
be fruitfully studied through text analysis, we detail four
theoretical areas of consumer research that link with linguistic dimensions of semantics, pragmatics, and syntax.
1278 JOURNAL OF CONSUMER RESEARCH
Downloaded from https://academic.oup.com/jcr/article-abstract/44/6/1274/4283031
by Galter Health Sciences Library, Northwestern Univ. user
on 15 June 2018
Specifically, attention can be examined through semantics,
processing through syntax, interpersonal dynamics through
pragmatics, and group-level characteristics through semantics and higher-order combinations of these dimensions.
Attention
The first area where text analysis is potentially valuable
to consumer research is in the study of attention. Consumer
attention is important in the evaluation of products and
experiences, self-awareness, attitude formation, and attribution, to name only a few domains. Language represents
attention in two ways. When consumers are thinking of or
attending to an issue, they tend to express it in words.
Conversely, when consumers are exposed to a word, they
are more likely to attend to it. In this way, researchers can
measure what concepts constitute attention in a given context, study how attention changes over time, and evaluate
how concepts are related to others in a semantic network.
Through semantics, researchers can measure temporal, spatial, and self-focus, and in contrast to self-reports, text
analysis can reveal patterns of attention or focus of which
the speaker may not be conscious (Mehl 2006).
Semantics, the study of word meaning, links language
with attention. From the perspective of semantics, a word
carries meaning over multiple, different contexts, and
humans store that information in memory. Word frequency, measuring how frequently a word occurs in text, is
one way of measuring attention and then further mapping a
semantic network. For example, based on the idea that people discuss the attributes that are top of mind when thinking of a particular car, Netzer et al. (2012) produce a
positioning map of car attributes from internet message
board data using supervised learning.
Researchers can infer the meaning of the word, what linguists and philosophers call the sense (Frege 1892/1948),
through its repeated and systematic co-occurrence with a
system of other words based on the linguistic principle of
holism (Quine 1970). For example, if the word “Honda” is
continually and repeatedly associated with “safety,” one can
infer that these concepts are related in consumers’ minds
such that Honda means safety to a significant number of
consumers. In this way, one can determine the sense through
the context of words around it (Frege 1892/1948; Quine
1970), and this holism is a critical property from a methodological perspective because it implies that one can derive the
meaning of a word by studying its collocation with surrounding words (Neuman, Turney, and Cohen 2012; Pollach
2012). Due to the inherent holism of language, semantic
analysis is a natural fit with spreading activation models of
memory and association (Collins and Loftus 1975).
Text analysis can also measure implicit rather than
explicit attention through semantics. The focus of consumer attention on the self as opposed to others (Spiller
and Belogolova 2016) and temporal focus, such as
psychological distance and construal (Snefjella and
Kuperman 2015), are patterns that may not be recognized
by consumers themselves, but can be made manifest
through text analysis (Mehl 2006). For example, a wellknown manipulation of self-construal is the “I” versus
“we” sentence completion task (Gardner, Gabriel, and Lee
1999). Conversely, text analysis can help detect differences
in self-construal using measures for these words.
Language represents the focus of consumer attention,
but it can also direct consumer attention through semantic
framing (Lakoff 2014; Lakoff and Ferguson 2015). For example, when Oil of Olay claims to “reverse the signs of
aging” in the United States, but the same product claims to
“reduce the signs of aging” in France, the frame activates
different meaning systems—“reversing” being more associated with agency, and “reduction” being a more passive
framing. As ample research in framing and memory has
shown, consumers’ associative networks can be activated
when they see a particular word, which in turn may affect
attitudes (Humphreys and Latour 2013; Lee and Labroo
2004; Valentino 1999), goal pursuit (Chartrand and Bargh
1996; Chartrand et al. 2008), and regulatory focus (Labroo
and Lee 2006; Lee and Aaker 2004).
Language not only represents the cognitive components of
attention, but also reflects the emotion consumers may feel in
a particular context. Researchers have used automated text
analysis to study the role of emotional language in the spread
of viral content (Berger and Milkman 2012), response to national tragedies (Dore´ et al. 2015), and well-being (Settanni
and Marengo 2015). As we will later discuss, researchers use
a broad range of sentiment dictionaries to measure emotion
and evaluate how consumer attitudes may change over time
(Hopkins and King 2010), in certain contexts (Dore´ et al.
2015), or due to certain interpersonal groupings. Building on
these approaches, researchers studying narrative have used
the flow of emotional language (e.g., from more to less emotional words) to code different story arcs, such as comedy
(positive to negative to positive) versus tragedy (negative to
positive to negative) (Van Laer et al. 2017).